= Architecture =

== The network ==

Vala is an object-oriented language, and so I designed my program around a series of classes.

The first class I've created is the [[Neuron.html|Neuron]]. It is exactly what it sounds like - the archetype of every single neuron in a network. Embedded into it is the [[Neuron.Synapse.html|Synapse]] structure, which in turn describes inter-neuron connections, including the flow direction of the signal. Synapse references are held in dynamic arrays inside the Neurons. A neuron's signal function may be linear, or sigmoidal (i.e. processed with the //tanh()// function).

Derived from the Neuron are the [[ImagePixel.html|ImagePixel]] class, which reads a single pixel of a [[CharacterRenderer.html|CharacterRenderer]]'s image at the specified coordinates, and the [[BiasNeuron.html|BiasNeuron]] class, which is a special case of a singleton-like neuron that provides a constant signal with a value of 1.0 and is connected to every neuron in the network, offering bias of the signal function depending on the weight assigned to its synapse.

Neurons are organized into [[NeuralNetwork.html|NeuralNetwork]]s. An object of this class holds an array of network layers, which are arrays of Neurons themselves. Upon its construction, a single layer of linear neurons is created, which becomes the output layer of the network. Layers are added in a stack-like way, and the one which is added last becomes the input layer. It is important, then, to add the layer composed of [[ImagePixel.html|ImagePixel]]s last. A neural network's layout and characteristics may be manipulated using the program's GUI.

There are as many ImagePixel neurons in the input layer as there are pixels in the character glyph bitmap, and as many output neurons as size of the alphabet the network is trained to detect. In terms of electronics, the network's output layer may be viewed as a multiplexer, which sets the output line corresponding to a recognized character to the high state. The network may not recognize any characters in the input bitmap (i.e. signal on all output neurons is below detection threshold), recognize one character (i.e. only one output neuron has a signal above the detection threshold value), or the result may be ambiguous (i.e. more than one output neuron with signal above detection threshold).

When the network is being run, its [[NeuralNetwork.run.html|run()]] method requests the output layer neurons to calculate their signal values. This causes them to request the signals from the layers below and so on - the network generates its output recursively. Same applies for training - the [[NeuralNetwork.train.html|train()]] method runs the network, calculates error at output, and then backpropagates it by initiating a recursive weight update.

== Character sample corpus ==

Instead of gathering hundreds or thousands of character glyph samples to train the network on, I decided to generate them on my own from fonts installed on the system and providing tools to add noise to them. Currently, the [[CharacterRenderer.html|CharacterRenderer]] class offers facilities to add per-pixel uniform noise and positional jitter (random position offset). Its parameters (font face, style, size, noise and jitter amounts) may be tweaked from the program's GUI. The glyphs are rendered to an off-screen buffer for the ImagePixels to access, as well as blitted onto UI widgets.

== Signal representation ==

All signals in the program are represented as double precision floating point numbers. Input values (i.e. character bitmap pixel luminance) are normalized to the [-1..1] range (-1.0 is black, 1.0 is white, 0.0 is medium gray). The networks are trained toward -1.0 for characters that should not be detected, and toward 1.0 for characters that should be detected. Detection threshold value is configurable by user, and defaults to 0.3.

[[index.valadoc|Index]] · Previous: [[intro.valadoc|Introduction]] · Next: [[extern_spec.valadoc|External specification]]
